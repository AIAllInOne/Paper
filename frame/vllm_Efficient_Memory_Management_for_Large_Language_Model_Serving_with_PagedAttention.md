# Efficient Memory Management for Large Language Model Serving with PagedAttention

https://arxiv.org/pdf/2309.06180

一文通透vLLM与其核心技术PagedAttention：减少KV Cache碎片、提高GPU显存利用率(推理加速利器)
https://blog.csdn.net/v_JULY_v/article/details/144218958
